   ExperimentSpec{
      'algo_name': Batch ActorCritic
      'comment': Discounted-Bootstrap-target Farsighted
      'paramameter_set_name': Batch-AAC-Split-nn
      'rerun_tag': BBSPL-A
      'rerun_idx': 1
      'isTestRun': False
      'prefered_environment': CartPole-v0
      'expected_reward_goal': 200
      'show_plot': False
      'batch_size_in_ts': 3000
      'max_epoch': 50
      'discout_factor': 0.9999
      'learning_rate': 0.01
      'discounted_reward_to_go': True
      'theta_nn_h_layer_topo': (16, 32, 64)
      'random_seed': 0
      'theta_hidden_layers_activation': <function relu at 0x128d41268>
      'theta_output_layers_activation': None
      'render_env_every_What_epoch': 100
      'log_every_step': 1000
      'print_metric_every_what_epoch': 2
      'Target': TargetType.Bootstrap
      'Network': NetworkType.Split
      'critic_learning_rate': 0.001
      'critique_loop_len': 120
      'note': Both loss have a lot less variance. The algo take more time to converge. relu seams to work better
   }