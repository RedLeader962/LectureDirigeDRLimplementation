   ExperimentSpec{
      'algo_name': Batch ActorCritic
      'comment': Bootstrap-Tiny-Batch-WORKING
      'paramameter_set_name': Batch-AAC-Shared-nn
      'rerun_tag': BSHA-A
      'rerun_idx': 1
      'isTestRun': False
      'prefered_environment': CartPole-v0
      'expected_reward_goal': 200
      'show_plot': False
      'batch_size_in_ts': 200
      'max_epoch': 400
      'discout_factor': 0.999
      'learning_rate': 0.001
      'discounted_reward_to_go': True
      'theta_nn_h_layer_topo': (60, 60)
      'random_seed': 0
      'theta_hidden_layers_activation': <function leaky_relu at 0x1225b6268>
      'theta_output_layers_activation': None
      'render_env_every_What_epoch': 100
      'log_every_step': 1000
      'print_metric_every_what_epoch': 8
      'Target': TargetType.Bootstrap
      'Network': NetworkType.Shared
      'critic_learning_rate': 0.0001
      'critique_loop_len': 100
      'note': Converge aparently faster.Does not learn on large batch! Work only on tiny batch (more or less 1 trajectory)Use small hlayer topo.Require small learning rate.Extremely sensible to hyper param tuning.Can possibly not learn at all on different run with same hparam probably because of unlucky grpah initialisation or unlucky initial state
   }