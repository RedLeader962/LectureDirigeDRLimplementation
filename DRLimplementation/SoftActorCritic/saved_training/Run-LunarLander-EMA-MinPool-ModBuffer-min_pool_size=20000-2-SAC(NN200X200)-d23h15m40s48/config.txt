   ExperimentSpec{
      'algo_name': Soft Actor Critic
      'comment': NN200X200
      'paramameter_set_name': SAC
      'rerun_tag': LunarLander-EMA-MinPool-ModBuffer-min_pool_size=20000
      'rerun_idx': 2
      'isTestRun': False
      'prefered_environment': LunarLanderContinuous-v2
      'expected_reward_goal': 190
      'show_plot': False
      'batch_size_in_ts': 200
      'max_epoch': 50
      'discout_factor': 0.99
      'learning_rate': 0.003
      'discounted_reward_to_go': True
      'theta_nn_h_layer_topo': (200, 200)
      'random_seed': 0
      'theta_hidden_layers_activation': <function relu at 0x139a8f510>
      'theta_output_layers_activation': None
      'render_env_every_What_epoch': 5
      'log_metric_interval': 500
      'print_metric_every_what_epoch': 5
      'max_trj_steps': 1000
      'AgentType': <class 'SoftActorCritic.SoftActorCriticAgent.SoftActorCriticAgent'>
      'timestep_per_epoch': 5000
      'reward_scaling': 40.0
      'critic_learning_rate': 0.003
      'max_gradient_step_expected': 250000
      'actor_lr_decay_rate': 1.0
      'critic_lr_decay_rate': 1.0
      'target_smoothing_coefficient': 0.005
      'target_update_interval': 1
      'gradient_step_interval': 1
      'alpha': 1.0
      'max_eval_trj': 10
      'pool_capacity': 50000
      'min_pool_size': 20000
      'phi_nn_h_layer_topo': (200, 200)
      'phi_hidden_layers_activation': <function relu at 0x139a8f510>
      'phi_output_layers_activation': None
      'psi_nn_h_layer_topo': (200, 200)
      'psi_hidden_layers_activation': <function relu at 0x139a8f510>
      'psi_output_layers_activation': None
      'render_env_eval_interval': 5
      'note': 
      'SpinningUpSquashing': False
      'SpinningUpGaussian': False
   }