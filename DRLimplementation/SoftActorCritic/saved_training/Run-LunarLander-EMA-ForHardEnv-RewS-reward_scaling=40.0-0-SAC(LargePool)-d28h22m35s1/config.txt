   ExperimentSpec{
      'algo_name': Soft Actor Critic
      'comment': LargePool
      'paramameter_set_name': SAC
      'rerun_tag': LunarLander-EMA-ForHardEnv-RewS-reward_scaling=40.0
      'rerun_idx': 0
      'isTestRun': False
      'prefered_environment': LunarLanderContinuous-v2
      'expected_reward_goal': 190
      'show_plot': False
      'batch_size_in_ts': 200
      'max_epoch': 500
      'discout_factor': 0.99
      'learning_rate': 0.003
      'discounted_reward_to_go': True
      'theta_nn_h_layer_topo': (200, 200)
      'random_seed': 0
      'theta_hidden_layers_activation': <function relu at 0x134a2a598>
      'theta_output_layers_activation': None
      'render_env_every_What_epoch': 5
      'log_metric_interval': 500
      'print_metric_every_what_epoch': 5
      'max_trj_steps': 1000
      'AgentType': <class 'SoftActorCritic.SoftActorCriticAgent.SoftActorCriticAgent'>
      'timestep_per_epoch': 1000
      'reward_scaling': 40.0
      'critic_learning_rate': 0.003
      'max_gradient_step_expected': 500000
      'actor_lr_decay_rate': 1.0
      'critic_lr_decay_rate': 1.0
      'target_smoothing_coefficient': 0.005
      'target_update_interval': 1
      'gradient_step_interval': 1
      'alpha': 1.0
      'max_eval_trj': 10
      'pool_capacity': 200000
      'min_pool_size': 80000
      'phi_nn_h_layer_topo': (200, 200)
      'phi_hidden_layers_activation': <function relu at 0x134a2a598>
      'phi_output_layers_activation': None
      'psi_nn_h_layer_topo': (200, 200)
      'psi_hidden_layers_activation': <function relu at 0x134a2a598>
      'psi_output_layers_activation': None
      'render_env_eval_interval': 5
      'note': 
      'hardEnvVersion': False
   }