   ExperimentSpec{
      'algo_name': Soft Actor Critic
      'comment': 
      'paramameter_set_name': SAC
      'rerun_tag': RewardScaleTest
      'rerun_idx': 0
      'isTestRun': False
      'prefered_environment': Pendulum-v0
      'expected_reward_goal': -561.0
      'show_plot': False
      'batch_size_in_ts': 100
      'max_epoch': 50
      'discout_factor': 0.99
      'learning_rate': 0.003
      'discounted_reward_to_go': True
      'theta_nn_h_layer_topo': (16,)
      'random_seed': 0
      'theta_hidden_layers_activation': <function relu at 0x12f1d21e0>
      'theta_output_layers_activation': None
      'render_env_every_What_epoch': 5
      'log_metric_interval': 50
      'print_metric_every_what_epoch': 10
      'AgentType': <class 'SoftActorCritic.SoftActorCriticAgent.SoftActorCriticAgent'>
      'timestep_per_epoch': 5000
      'reward_scaling': 1.0
      'critic_learning_rate': 0.003
      'max_gradient_step_expected': 250000
      'actor_lr_decay_rate': 1.0
      'critic_lr_decay_rate': 1.0
      'target_smoothing_coefficient': 0.99
      'target_update_interval': 1
      'gradient_step_interval': 1
      'alpha': 0.2
      'max_eval_trj': 20
      'pool_capacity': 1000000
      'min_pool_size': 10000
      'phi_nn_h_layer_topo': (16,)
      'phi_hidden_layers_activation': <function relu at 0x12f1d21e0>
      'phi_output_layers_activation': None
      'psi_nn_h_layer_topo': (16,)
      'psi_hidden_layers_activation': <function relu at 0x12f1d21e0>
      'psi_output_layers_activation': None
      'render_env_eval_interval': 10
      'note': (Proof of life) Should reach Avg Return close to ~ -560
   }