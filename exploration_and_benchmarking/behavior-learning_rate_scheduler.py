# coding=utf-8

if __name__ == '__main__':

    """
    Exploration related to the implementation and usage of the learning_rate_scheduler() fct 
    in /DRLimplementation/blocAndTools/buildingbloc.py
    
    
    -------------------------------------------------------------------------------------------------------------------    
    (lr=1e-1, decay_rate=1e-1, max_epoch=20) --> close to 1e-2 after 20 epoch
    
    ```python

        lr_scheduler_test(
            learning_rate=1e-1, 
            decay_rate=1e-1,    # <-- 1e-1 == 0.1 == 1/10 ==> (bigger decay rate)    
            global_step=i, 
            decay_steps=20      # <-- (!) max_epoch
            )

        > 0.1
        > 0.08912509381337456
        > 0.07943282347242815
        > 0.07079457843841379
        > 0.06309573444801933
        > 0.05623413251903491
        > 0.05011872336272724
        > 0.04466835921509632
        > 0.03981071705534973
        > 0.03548133892335755
        > 0.0316227766016838
        > 0.02818382931264454
        > 0.0251188643150958
        > 0.022387211385683396
        > 0.019952623149688802
        > 0.01778279410038923
        > 0.015848931924611134
        > 0.014125375446227545
        > 0.012589254117941673
        > 0.011220184543019637
    ```
    
    
    
    -------------------------------------------------------------------------------------------------------------------
    (lr=1e-1, decay_rate=1e-3, max_epoch=20) --> ~1e-4 after 20 epoch (0.0001412537544622755)
    
    ```python    

        lr_scheduler_test(
            learning_rate=1e-1, 
            decay_rate=1e-3,    # <-- 1e-3 == 0.001 == 1/1000 ==> (smaller decay rate)
            global_step=i, 
            decay_steps=20      # <-- (!) max_epoch
            )

        > 0.1
        > 0.07079457843841379
        > 0.05011872336272723
        > 0.03548133892335755
        > 0.0251188643150958
        > 0.01778279410038923
        > 0.012589254117941673
        > 0.008912509381337457
        > 0.006309573444801932
        > 0.0044668359215096305
        > 0.0031622776601683794
        > 0.002238721138568339
        > 0.0015848931924611139
        > 0.0011220184543019633
        > 0.0007943282347242817
        > 0.0005623413251903491
        > 0.0003981071705534972
        > 0.00028183829312644545
        > 0.00019952623149688796
        > 0.0001412537544622755
    ```
    -------------------------------------------------------------------------------------------------------------------

    """

    def lr_scheduler_test(learning_rate: float, decay_rate: int, global_step: int, decay_steps: int):
        decayed_learning_rate = learning_rate * decay_rate**(global_step / decay_steps)
        return decayed_learning_rate


    the_max_epoch = 100
    for i in range(the_max_epoch):
        print(lr_scheduler_test(1e-1, 1e-2, i, the_max_epoch))
